{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cho Preprocessing\n",
    "By _sourced_ dataset, we mean the dataset that was retrieved from Calderon and Ventures' study. On the other hand, the _raw_ dataset comes from our own retrieval of the dataset from the Yeung et al (https://faculty.washington.edu/kayee/cluster/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Trailing Whitespace of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_cho_dataset():\n",
    "  with open('../dataset/raw/cho_original.txt', 'r') as file:\n",
    "    lines = [line.strip() for line in file]\n",
    "  with open ('../dataset/raw/cho_cleaned.txt', 'w') as file:\n",
    "    for line in lines:\n",
    "      file.write(line + '\\n')\n",
    "\n",
    "def clean_sourced_cho_dataset():\n",
    "  lines = []\n",
    "  with open('../dataset/sourced/cho_ventures.txt', 'r') as file:\n",
    "    for index, line in enumerate(file):\n",
    "      if index == 0:\n",
    "        # In the header row, we omit the extraneous 'Gp' column\n",
    "        header = line.strip().split('\\t')\n",
    "        header.remove('Gp')\n",
    "        lines.append('\\t'.join(header))\n",
    "      else:\n",
    "        # Else, we just append the line to the list of lines\n",
    "        lines.append(line.strip())\n",
    "\n",
    "  with open ('../dataset/sourced/cho_ventures_cleaned.txt', 'w') as file:\n",
    "    for line in lines:\n",
    "      file.write(line + '\\n')\n",
    "\n",
    "def clean_sourced_kegg_dataset():\n",
    "  lines = []\n",
    "  with open('../dataset/sourced/kegg_ventures.txt', 'r') as file:\n",
    "    for index, line in enumerate(file):\n",
    "      if index == 0:\n",
    "        # In the header row, we omit the extraneous 'Gp' column\n",
    "        header = line.strip().split('\\t')\n",
    "        header.remove('Gp')\n",
    "        lines.append('\\t'.join(header))\n",
    "      else:\n",
    "        # Else, we just append the line to the list of lines\n",
    "        lines.append(line.strip())\n",
    "\n",
    "  with open ('../dataset/sourced/kegg_ventures_cleaned.txt', 'w') as file:\n",
    "    for line in lines:\n",
    "      file.write(line + '\\n')\n",
    "# Generate the cleaned dataset. We only need to run this once.\n",
    "# clean_cho_dataset()\n",
    "# clean_sourced_cho_dataset()\n",
    "# clean_sourced_kegg_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Raw Cho vs Sourced Cho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Gene  Gp       c1       c2       c3       c4       c5       c6       c7  \\\n",
      "0  YDL179w   1 -0.75808 -0.90319 -0.98935 -0.73995 -0.67193 -0.12777 -0.95307   \n",
      "1  YLR079w   1 -0.48845 -0.70828 -0.47688 -0.65814 -0.45374 -0.47302 -0.71214   \n",
      "2  YER111c   1 -0.42218  0.23887  1.84427 -0.02083 -0.61105 -0.65827 -0.79992   \n",
      "3  YBR200w   1  0.09824  0.55258 -0.89641 -1.19111 -1.11744 -0.76133  0.09824   \n",
      "4  YJL194w   1 -1.29859  1.71422 -0.52745 -1.11926 -0.63505 -0.02532 -0.36605   \n",
      "\n",
      "        c8       c9      c10      c11      c12      c13      c14      c15  \\\n",
      "0 -1.01656  0.79730  2.11688  1.98537  0.61591  0.56603 -0.13684 -0.52228   \n",
      "1 -1.02839  0.24048  3.11376  1.28952  0.44874  0.04379 -0.31104 -0.30332   \n",
      "2 -0.39857 -0.09166  2.03314  1.58457  0.68744  0.14443 -0.72910 -1.46097   \n",
      "3  2.16120  1.46126  1.03148  0.67537 -0.33155 -0.60170 -1.39987 -0.42978   \n",
      "4 -0.76059  1.44522  2.05496 -0.22259  0.20782 -0.36605  0.01055 -0.77852   \n",
      "\n",
      "       c16      c17  \n",
      "0 -0.05068  0.78823  \n",
      "1 -0.34575  0.82285  \n",
      "2 -0.82353 -0.51662  \n",
      "3 -0.15963  0.81045  \n",
      "4 -0.49159  1.15829  \n",
      "========================================\n",
      "No null values in raw_cho_data!\n",
      "Gene    0\n",
      "Gp      0\n",
      "c1      0\n",
      "c2      0\n",
      "c3      0\n",
      "c4      0\n",
      "c5      0\n",
      "c6      0\n",
      "c7      0\n",
      "c8      0\n",
      "c9      0\n",
      "c10     0\n",
      "c11     0\n",
      "c12     0\n",
      "c13     0\n",
      "c14     0\n",
      "c15     0\n",
      "c16     0\n",
      "c17     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "raw_cho_data = pd.read_csv('../dataset/raw/cho_cleaned.txt', sep='\\t', header=0)\n",
    "print(raw_cho_data.head())\n",
    "print(\"========================================\")\n",
    "print(\"No null values in raw_cho_data!\")\n",
    "print(raw_cho_data.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Gene  Level_1  Level_2       c1       c2       c3       c4       c5  \\\n",
      "0  YDL179w        1       11 -0.75808 -0.90319 -0.98935 -0.73995 -0.67193   \n",
      "1  YLR079w        1       11 -0.48845 -0.70828 -0.47688 -0.65814 -0.45374   \n",
      "2  YER111c        1       11 -0.42218  0.23887  1.84427 -0.02083 -0.61105   \n",
      "3  YBR200w        1       12  0.09824  0.55258 -0.89641 -1.19111 -1.11744   \n",
      "4  YJL194w        1       13 -1.29859  1.71422 -0.52745 -1.11926 -0.63505   \n",
      "\n",
      "        c6       c7       c8       c9      c10      c11      c12      c13  \\\n",
      "0 -0.12777 -0.95307 -1.01656  0.79730  2.11688  1.98537  0.61591  0.56603   \n",
      "1 -0.47302 -0.71214 -1.02839  0.24048  3.11376  1.28952  0.44874  0.04379   \n",
      "2 -0.65827 -0.79992 -0.39857 -0.09166  2.03314  1.58457  0.68744  0.14443   \n",
      "3 -0.76133  0.09824  2.16120  1.46126  1.03148  0.67537 -0.33155 -0.60170   \n",
      "4 -0.02532 -0.36605 -0.76059  1.44522  2.05496 -0.22259  0.20782 -0.36605   \n",
      "\n",
      "       c14      c15      c16      c17  \n",
      "0 -0.13684 -0.52228 -0.05068  0.78823  \n",
      "1 -0.31104 -0.30332 -0.34575  0.82285  \n",
      "2 -0.72910 -1.46097 -0.82353 -0.51662  \n",
      "3 -1.39987 -0.42978 -0.15963  0.81045  \n",
      "4  0.01055 -0.77852 -0.49159  1.15829  \n",
      "========================================\n",
      "No null values in sourced_cho_data!\n",
      "Gene       0\n",
      "Level_1    0\n",
      "Level_2    0\n",
      "c1         0\n",
      "c2         0\n",
      "c3         0\n",
      "c4         0\n",
      "c5         0\n",
      "c6         0\n",
      "c7         0\n",
      "c8         0\n",
      "c9         0\n",
      "c10        0\n",
      "c11        0\n",
      "c12        0\n",
      "c13        0\n",
      "c14        0\n",
      "c15        0\n",
      "c16        0\n",
      "c17        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sourced_cho_data = pd.read_csv('../dataset/sourced/cho_ventures_cleaned.txt', sep='\\t')\n",
    "print(sourced_cho_data.head())\n",
    "print(\"========================================\")\n",
    "print(\"No null values in sourced_cho_data!\")\n",
    "print(sourced_cho_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "What genes are missing in the sourced dataset that is present in the raw dataset?\n",
      "Count:  214\n",
      "10     YGR044c\n",
      "11     YML109w\n",
      "15     YNR001c\n",
      "16     YKL150w\n",
      "18     YOR065w\n",
      "        ...   \n",
      "379    YOL070c\n",
      "380    YLR297W\n",
      "381    YHL028W\n",
      "382    YHR151C\n",
      "383    YNL058C\n",
      "Name: Gene, Length: 214, dtype: object\n"
     ]
    }
   ],
   "source": [
    "raw_cho_data_genes = raw_cho_data['Gene']\n",
    "sourced_cho_data_genes = sourced_cho_data['Gene']\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"What genes are missing in the sourced dataset that is present in the raw dataset?\")\n",
    "missing_genes = raw_cho_data_genes[~raw_cho_data_genes.isin(sourced_cho_data_genes)]\n",
    "print(\"Count: \", missing_genes.count())\n",
    "print(missing_genes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
